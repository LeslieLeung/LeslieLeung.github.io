[{"title":"meow","url":"/2019/10/14/meow/","content":"\n我们一起喵喵喵"},{"url":"/2019/10/14/TensorFlow解决MNIST数字识别问题/","content":"# TensorFlow解决MNIST数字识别问题\n\n## 废话\n\n这个MNIST数字识别问题是我实现的第一个神经网络，虽然过程基本上都是对着书上的代码敲，但还是对神经网络的训练过程有了一定的了解，同时也复习了前面几章关于TensorFlow和神经网络的一些基本概念。\n\n## MNIST介绍\n\nMNIST是一个非常有名的手写体数字识别数据集，通常用来作为深度学习的入门样例。\n\nMNIST的数据集可以在[http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)下载\n\nTensorFlow提供了一个类来处理MNIST数据，能够自动下载并转化MNIST数据的格式。\n\n\n\n## 训练神经网络\n\n直接先贴代码\n\n```\nimport tensorflow as tf\nfrom tensorflow.examples.tutorials.mnist import input_data\n\n# MNIST相关常数\nINPUT_NODE = 784\nOUTPUT_NODE = 10\n\n# 神经网络参数\nLAYER1_NODE = 500\nBATCH_SIZE = 100\nLEARNING_RATE_BASE = 0.8\nLEARNING_RATE_DECAY = 0.99\nREGULARIZATION_RATE = 0.0001\nTRAINING_STEPS = 30000\nMOVING_AVERAGE_DECAY = 0.99\n\n\ndef inference(input_tensor, avg_class, weights1, biases1, weights2, biases2):\n    if avg_class == None:\n        layer1 = tf.nn.relu(tf.matmul(input_tensor, weights1) + biases1)\n        return tf.matmul(layer1, weights2) + biases2\n    else:\n        layer1 = tf.nn.relu(\n            tf.matmul(input_tensor, avg_class.average(weights1)) + avg_class.average(biases1)\n        )\n        return tf.matmul(layer1, avg_class.average(weights2)) + avg_class.average(biases2)\n\n\ndef train(mnist):\n    x = tf.placeholder(tf.float32, [None, INPUT_NODE], name='x-input')\n    y_ = tf.placeholder(tf.float32, [None, OUTPUT_NODE], name='y-input')\n\n    weights1 = tf.Variable(\n        tf.truncated_normal([INPUT_NODE, LAYER1_NODE], stddev=0.1))\n    biases1 = tf.Variable(tf.constant(0.1, shape=[LAYER1_NODE]))\n    weights2 = tf.Variable(\n        tf.truncated_normal([LAYER1_NODE, OUTPUT_NODE], stddev=0.1))\n    biases2 = tf.Variable(tf.constant(0.1, shape=[OUTPUT_NODE]))\n\n    y = inference(x, None, weights1, biases1, weights2, biases2)\n\n    global_step = tf.Variable(0, trainable=False)\n\n    variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)\n\n    variables_averages_op = variable_averages.apply(tf.trainable_variables())\n\n    average_y = inference(x, variable_averages, weights1, biases1, weights2, biases2)\n\n    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, 1))\n    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n\n    regularizer = tf.contrib.layers.l2_regularizer(REGULARIZATION_RATE)\n    regularization = regularizer(weights1) + regularizer(weights2)\n    loss = cross_entropy_mean + regularization\n\n    learning_rate = tf.train.exponential_decay(\n        LEARNING_RATE_BASE, global_step, mnist.train.num_examples, LEARNING_RATE_DECAY\n    )\n\n    train_step = tf.train.GradientDescentOptimizer(learning_rate) \\\n        .minimize(loss, global_step=global_step)\n\n    with tf.control_dependencies([train_step, variables_averages_op]):\n        train_op = tf.no_op(name='train')\n\n    correct_prediction = tf.equal(tf.argmax(average_y, 1), tf.argmax(y_, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n    with tf.Session() as sess:\n        tf.global_variables_initializer().run()\n        validate_feed = {\n            x: mnist.validation.images,\n            y_: mnist.validation.labels\n        }\n\n        test_feed = {x: mnist.test.images, y_: mnist.test.labels}\n\n        for i in range(TRAINING_STEPS):\n            if i % 1000 == 0:\n                validate_acc = sess.run(accuracy, feed_dict=validate_feed)\n                test_acc = sess.run(accuracy, feed_dict=test_feed)\n                print(\"After %d training step(s), validation accuracy \"\n                      \"using average model is %g , test accuracy is %g\" % (i, validate_acc, test_acc))\n            xs, ys = mnist.train.next_batch(BATCH_SIZE)\n            sess.run(train_op, feed_dict={x: xs, y_: ys})\n\n        test_acc = sess.run(accuracy, feed_dict=test_feed)\n        print(\"After %d training step(s), test accuracy using average model is %g\" % (TRAINING_STEPS, test_acc))\n\n\ndef main(argv=None):\n    mnist = input_data.read_data_sets(\"/temp/data\", one_hot=True)\n    train(mnist)\n\n\nif __name__ == '__main__':\n    tf.app.run()\n```\n然后是输出结果\n\n```python\nExtracting /temp/data\\train-images-idx3-ubyte.gz\nWARNING:tensorflow:From C:/Users/lesil/PycharmProjects/matchzoo/MNIST.py:93: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use alternatives such as official/mnist/dataset.py from tensorflow/models.\nWARNING:tensorflow:From C:\\Users\\lesil\\Anaconda3\\envs\\matchzoo\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease write your own downloading logic.\nWARNING:tensorflow:From C:\\Users\\lesil\\Anaconda3\\envs\\matchzoo\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.data to implement this functionality.\nExtracting /temp/data\\train-labels-idx1-ubyte.gz\nWARNING:tensorflow:From C:\\Users\\lesil\\Anaconda3\\envs\\matchzoo\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.data to implement this functionality.\nWARNING:tensorflow:From C:\\Users\\lesil\\Anaconda3\\envs\\matchzoo\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.one_hot on tensors.\nExtracting /temp/data\\t10k-images-idx3-ubyte.gz\nExtracting /temp/data\\t10k-labels-idx1-ubyte.gz\nWARNING:tensorflow:From C:\\Users\\lesil\\Anaconda3\\envs\\matchzoo\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use alternatives such as official/mnist/dataset.py from tensorflow/models.\nWARNING:tensorflow:From C:\\Users\\lesil\\Anaconda3\\envs\\matchzoo\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n2019-08-11 11:43:46.478172: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\nAfter 0 training step(s), validation accuracy using average model is 0.1596 , test accuracy is 0.1702\nAfter 1000 training step(s), validation accuracy using average model is 0.9766 , test accuracy is 0.975\nAfter 2000 training step(s), validation accuracy using average model is 0.9812 , test accuracy is 0.9809\nAfter 3000 training step(s), validation accuracy using average model is 0.9828 , test accuracy is 0.9828\nAfter 4000 training step(s), validation accuracy using average model is 0.9836 , test accuracy is 0.9837\nAfter 5000 training step(s), validation accuracy using average model is 0.9834 , test accuracy is 0.9835\nAfter 6000 training step(s), validation accuracy using average model is 0.985 , test accuracy is 0.985\nAfter 7000 training step(s), validation accuracy using average model is 0.9846 , test accuracy is 0.9845\nAfter 8000 training step(s), validation accuracy using average model is 0.9852 , test accuracy is 0.9842\nAfter 9000 training step(s), validation accuracy using average model is 0.9844 , test accuracy is 0.9852\nAfter 10000 training step(s), validation accuracy using average model is 0.9858 , test accuracy is 0.9844\nAfter 11000 training step(s), validation accuracy using average model is 0.9854 , test accuracy is 0.9845\nAfter 12000 training step(s), validation accuracy using average model is 0.9862 , test accuracy is 0.984\nAfter 13000 training step(s), validation accuracy using average model is 0.9844 , test accuracy is 0.984\nAfter 14000 training step(s), validation accuracy using average model is 0.9854 , test accuracy is 0.9842\nAfter 15000 training step(s), validation accuracy using average model is 0.9862 , test accuracy is 0.9842\nAfter 16000 training step(s), validation accuracy using average model is 0.9862 , test accuracy is 0.9841\nAfter 17000 training step(s), validation accuracy using average model is 0.9856 , test accuracy is 0.9838\nAfter 18000 training step(s), validation accuracy using average model is 0.9848 , test accuracy is 0.9848\nAfter 19000 training step(s), validation accuracy using average model is 0.9858 , test accuracy is 0.9835\nAfter 20000 training step(s), validation accuracy using average model is 0.9864 , test accuracy is 0.9844\nAfter 21000 training step(s), validation accuracy using average model is 0.9868 , test accuracy is 0.9845\nAfter 22000 training step(s), validation accuracy using average model is 0.9856 , test accuracy is 0.9844\nAfter 23000 training step(s), validation accuracy using average model is 0.9858 , test accuracy is 0.9842\nAfter 24000 training step(s), validation accuracy using average model is 0.9862 , test accuracy is 0.9845\nAfter 25000 training step(s), validation accuracy using average model is 0.9862 , test accuracy is 0.9845\nAfter 26000 training step(s), validation accuracy using average model is 0.9858 , test accuracy is 0.9843\nAfter 27000 training step(s), validation accuracy using average model is 0.9864 , test accuracy is 0.984\nAfter 28000 training step(s), validation accuracy using average model is 0.9858 , test accuracy is 0.9843\nAfter 29000 training step(s), validation accuracy using average model is 0.9864 , test accuracy is 0.9842\nAfter 30000 training step(s), test accuracy using average model is 0.9846\n\nProcess finished with exit code 0\n```\n## 几个坑点\n\n* 书上的代码有部分缩进错误，在python中缩进错误是直接gg的。在这里要通过看训练的过程（也就是train函数的部分）纠正一下原本的缩进错误。\n* 在使用L2正则化损失函数时，注意是l2而不是12，因为这里ide没有补全提示_​_**_（为什么？）_****​**​比较容易出现typo。\n\n\n\n## 训练过程\n\n**​一轮训练的过程**\n\n​首先计算当前参数下神经网络前向传播的结果，然后在所有代表神经网络参数的变量上使用滑动平均，然后计算使用了滑动平均之后的前向传播\n\n\n"},{"title":"Hello World","url":"/2019/10/14/hello-world/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n"}]